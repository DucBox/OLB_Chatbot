import streamlit as st
from src.core.chat import chat_with_gpt
from src.utils.xml_utils import save_history_to_xml
from src.core.traffic_controller import queue_if_overloaded, check_and_dispatch

def chat_input(user_id: str, history_file_path):
    """
    Hi·ªÉn th·ªã √¥ chat v√† x·ª≠ l√Ω c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, tr·∫£ l·ªùi b·∫±ng GPT.
    T·ª± ƒë·ªông ƒëi·ªÅu ph·ªëi traffic theo t·∫£i h·ªá th·ªëng.
    """
    user_input = st.chat_input("Ask me anything...")

    if user_input:
        # ====== ƒêi·ªÅu ph·ªëi theo CPU/RAM ==========
        if queue_if_overloaded(user_id, query_type="chat"):
            st.warning("‚è≥ H·ªá th·ªëng ƒëang b·∫≠n. B·∫°n ƒëang ƒë∆∞·ª£c ƒë∆∞a v√†o h√†ng ch·ªù.")
            st.stop()

        if not check_and_dispatch(user_id):
            st.info("üîÑ Vui l√≤ng ƒë·ª£i v√†i gi√¢y, h·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông x·ª≠ l√Ω khi s·∫µn s√†ng.")
            st.stop()

        # ====== Hi·ªÉn th·ªã c√¢u h·ªèi ng∆∞·ªùi d√πng ======
        st.markdown(
            f'<div class="chat-container user"><div class="chat-bubble">{user_input}</div></div>',
            unsafe_allow_html=True
        )

        # Placeholder cho bot tr·∫£ l·ªùi
        bot_placeholder = st.empty()
        bot_placeholder.markdown(
            '<div class="chat-container bot"><div class="chat-bubble">ü§ñ Thinking...</div></div>',
            unsafe_allow_html=True
        )

        # ====== G·ªçi GPT ƒë·ªÉ x·ª≠ l√Ω ======
        response, updated_history = chat_with_gpt(user_input, st.session_state.chat_history, user_id)

        # Hi·ªÉn th·ªã ph·∫£n h·ªìi
        bot_placeholder.markdown(
            f'<div class="chat-container bot"><div class="chat-bubble">{response}</div></div>',
            unsafe_allow_html=True
        )

        # ====== L∆∞u v√†o session + file XML ======
        st.session_state.chat_history = updated_history
        save_history_to_xml(updated_history, path=history_file_path)

        st.rerun()
