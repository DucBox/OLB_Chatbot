import pandas as pd
import time
import re
import os
import time
from datetime import datetime
from src.utils.config import TABLE_NAMES
from src.utils.gg_sheet_utils import extract_google_sheet_id, group_rows_by_first_col_gap, fetch_sheet_metadata, select_target_sheet, fetch_sheet_values, process_and_save_all_tables, describe_table_briefly
from src.utils.utils import extract_table_by_coords, save_text_to_txt, convert_values_to_dataframe, normalize_text
from src.utils.text_chunking import chunk_text
from src.database.gg_sheet_connection import get_sheets_service
from src.services.embedding_handler import generate_embedding, store_embedding_to_firebase, embed_text

service = get_sheets_service()

def read_google_sheet_from_url(sheet_url: str, index: int):
    """
    Orchestrator: ƒê·ªçc d·ªØ li·ªáu t·ª´ Google Sheet, t√°ch b·∫£ng, l∆∞u file. G·ªçi c√°c h√†m x·ª≠ l√Ω con.
    """
    sheet_id = extract_google_sheet_id(sheet_url)
    metadata = fetch_sheet_metadata(service, sheet_id)
    total_sheets = len(metadata["sheets"])
    print(f"üìä Google Sheet th·ª±c t·∫ø c√≥ {total_sheets} sheet(s).")
    sheet = select_target_sheet(metadata, index)

    sheet_title = sheet['properties']['title']
    merges = sheet.get('merges', [])

    values = fetch_sheet_values(service, sheet_id, sheet_title)
    if not values:
        return []

    df = convert_values_to_dataframe(values)

    table_texts = process_and_save_all_tables(
                    df,
                    table_names=TABLE_NAMES,
                )

    return table_texts

def process_google_sheet_to_embedding(sheet_url: str, category: str, uploaded_by: str, max_sheets: int):
    """
    ƒê·ªçc Google Sheet nhi·ªÅu tab (sheet index), x·ª≠ l√Ω embedding t·ª´ng b·∫£ng.
    V·ªõi m·ªói b·∫£ng, sinh m√¥ t·∫£ ng·∫Øn qua GPT, r·ªìi chunk v√† embed l·∫°i (c√≥ context).
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    timestamp_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    chunk_global_index = 0

    service = get_sheets_service()
    sheet_id = extract_google_sheet_id(sheet_url)
    metadata = fetch_sheet_metadata(service, sheet_id)
    sheets = metadata["sheets"]
    total_sheets = len(sheets)
    print(f"üìä Google Sheet th·ª±c t·∫ø c√≥ {total_sheets} sheet(s).")

    for sheet_index in range(min(max_sheets, total_sheets)):
        sheet_title = sheets[sheet_index]["properties"]["title"]
        normalized_title = normalize_text(sheet_title)
        doc_id = f"{category}_{normalized_title}_{timestamp_id}"

        try:
            table_texts = read_google_sheet_from_url(sheet_url, sheet_index)

            for table_idx, table_text in enumerate(table_texts):
                if not table_text.strip():
                    print(f"‚ö†Ô∏è Sheet '{sheet_title}' - Table {table_idx} is empty. Skipped.")
                    continue

                print(f"üß† Calling GPT to describe Sheet '{sheet_title}' - Table {table_idx}...")
                brief = describe_table_briefly(table_text)
                chunks = chunk_text(table_text)
                total_parts = len(chunks)

                for i, chunk in enumerate(chunks):
                    enhanced_chunk = f"{brief}\n(PART {i+1}/{total_parts})\n{chunk}"
                    print("---------------")
                    print(enhanced_chunk)
                    chunk_id = f"{doc_id}_chunk_{chunk_global_index}"

                    metadata_obj = {
                        "doc_id": doc_id,
                        "doc_title": sheet_title,
                        "category": category,
                        "chunk_index": chunk_global_index,
                        "source_type": "google_sheet",
                        "timestamp": timestamp,
                        "sheet_index": sheet_index,
                        "table_index": table_idx,
                        "user_id": uploaded_by
                    }

                    try:
                        embedding, returned_chunk_id = embed_text(enhanced_chunk, chunk_id, metadata_obj)
                        print(f"‚úÖ {doc_id} - Table {table_idx} - Chunk {chunk_global_index} ‚Üí {returned_chunk_id}")
                    except Exception as e:
                        print(f"‚ùå [ERROR] Embed failed: {doc_id} - Table {table_idx} - Chunk {chunk_global_index}: {e}")

                    chunk_global_index += 1

        except Exception as e:
            print(f"‚ùå [ERROR] Sheet index {sheet_index} ('{sheet_title}') skipped: {e}")


# process_google_sheet_to_embedding('https://docs.google.com/spreadsheets/d/1x8vgWHd38bnxYeaRBg-3i1ONMvDJ2Oq2fmhPHLLB9KA/edit?gid=1932410194#gid=1932410194', 'EM_B·∫Øc_Kan', 'Duc', 3)